# -*- coding: utf-8 -*-
"""LSTM_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pnSmy0do1skDtrljFWz7pE2a_Klly8_F
"""

#Loading the Drive helper and mount
from google.colab import drive
#HERE Will prompt for authorisation
drive.mount('/content/drive')

"""### Libraries"""

import pandas as pd
import numpy as np
import math

import matplotlib.pyplot as plt
import matplotlib.pyplot as mpl
import seaborn as sns
import plotly.graph_objs as go

from datetime import datetime

from sklearn.model_selection import train_test_split 
from keras.preprocessing.sequence import TimeseriesGenerator
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import tensorflow as tf


from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from math import sqrt

from scipy.stats import pearsonr

mpl.rcParams['figure.figsize']= (10,8)
mpl.rcParams['axes.grid']= False

import warnings
warnings.filterwarnings("ignore")

path = '/content/drive/My Drive/Energy project/dataset.csv'
df = pd.read_csv(path, index_col=0, parse_dates=True)
#df.head(10)

"""### Data Preparation for LSTM model"""

final_df.query("PV_hoch > 7500")

#X = final_df[['phasor_diff1', 'PV_hoch']]
#y = final_df[['phasor_diff1']]

#features = scaled_data
#target = scaled_data[:,0]

#divide data into train and test
train_ind = int(len(final_df)*0.80)
train = final_df[:train_ind]
test = final_df[train_ind:]

print(train.shape)
print(test.shape)

from pylab import rcParams
rcParams['figure.figsize'] = 13, 4

plt.plot(train['phasor_diff1'], label='train data')
plt.plot(test['phasor_diff1'], label='test data')

plt.legend(shadow=True)
plt.xlabel('time')
plt.ylabel('phasor difference')

#scaler = MinMaxScaler()
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()

#from sklearn.preprocessing import StandardScaler
#scaler = StandardScaler()
scaled_train_data = scaler.fit_transform(train)
scaled_test_data = scaler.fit_transform(test)

x_train = scaled_train_data
y_train = scaled_train_data[:,0]

x_test = scaled_test_data
y_test = scaled_test_data[:,0]

win_length = 4616
batch_size = 32
num_features = 2
train_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(x_train, y_train, length=win_length, sampling_rate=1, batch_size=batch_size)
test_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(x_test, y_test, length=win_length, sampling_rate=1, batch_size=batch_size)
#val_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(x_val, y_val, length=win_length, sampling_rate=1, batch_size=batch_size)

model = tf.keras.Sequential()
model.add(tf.keras.layers.LSTM(64, activation='tanh', recurrent_activation='sigmoid',input_shape =(win_length, num_features), use_bias=True, kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',
    bias_initializer='zeros', unit_forget_bias=True,
    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,
    activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,
    bias_constraint=None,return_sequences=True))
model.add(tf.keras.layers.LSTM(32, activation='tanh', recurrent_activation='sigmoid',return_sequences=False))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(1))

"""### Helper to check generator dimensions"""

# check generator dimensions
for i in range(len(train_generator)):
    x, y = train_generator[i]
    print(x.shape, y.shape)

# check generator dimensions
for i in range(len(test_generator)):
    x, y = test_generator[i]
    print(x.shape, y.shape)

test_generator[0]

# check generator dimensions
for i in range(len(val_generator)):
    x, y = val_generator[i]
    print(x.shape, y.shape)

"""### LSTM model"""

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model.png', show_shapes=True)
from IPython.display import Image
Image(filename='model.png')

model.summary()

#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                                  #patience=2,
                                                  #mode='min')

model.compile(loss=tf.losses.MeanSquaredError(),
              optimizer=tf.optimizers.Adam(),
              metrics= [tf.metrics.MeanAbsoluteError()])

history = model.fit(train_generator, epochs=10,shuffle = False)

model.evaluate(test_generator, verbose=0)

train_predictions = model.predict(train_generator)

train_predictions.shape[0]

df_pred0 = pd.concat([pd.DataFrame(train_predictions), pd.DataFrame(x_train[:,1:][win_length:])], axis=1)

rev_trans0 = scaler.inverse_transform(df_pred0)

df_0 = train[train_predictions.shape[0]*-1:]

df_0['phasor_diff1_train'] = rev_trans0[:,0]

df_0= df_0.drop(['PV_hoch'], axis=1)
df_0

df_0[['phasor_diff1','phasor_diff1_train']].plot()

df_0['residual'] = [df_0['phasor_diff1'][i]- df_0['phasor_diff1_train'][i] for i in range(len(df_0['phasor_diff1']))]
df_0

df_0['Sum_residual_squared'] = df_0['residual']**2
df_0

std_res0 = sqrt(sum(df_0['Sum_residual_squared'])/(14048-2))
std_res0

"""### Make predictions"""

predictions = model.predict(test_generator)

predictions.shape[0]

df_pred = pd.concat([pd.DataFrame(predictions), pd.DataFrame(x_test[:,1:][win_length:])], axis=1)

rev_trans = scaler.inverse_transform(df_pred)

df_final = final_df[predictions.shape[0]*-1:]

df_final['phasor_diff1_pred'] = rev_trans[:,0]

df_final= df_final.drop(['PV_hoch'], axis=1)
df_final

#df_final = df_final[['phasor_diff1', 'phasor_diff1_pred']]
#df_final

df_final[['phasor_diff1','phasor_diff1_pred']].plot()

df_final['error'] = abs(df_final['phasor_diff1'] - df_final['phasor_diff1_pred'])/ df_final['phasor_diff1'] * 100
df_final

"""### Prediction evaluation

Plot  
1. e (n)  =  error/standard dev. for each step n ahead
2. a (k) = averaged error/standard deviation as function of k.

The forecast can be called reliable as long as  e and  a 
are smaller or comparable to  1,
"""

df_final ['forecast_error'] = [df_final['phasor_diff1'][i]- df_final['phasor_diff1_pred'][i] for i in range(len(df_final['phasor_diff1']))]

mpl.rcParams['figure.figsize']= (10,7)
df_final1 = df_final.reset_index()

steps1 = df_final1.head(50)


steps1['forecast_error'].plot()
plt.xlabel('steps', family='Arial', fontsize=10)
plt.ylabel('error', family='Arial', fontsize=10)
plt.show()

df_final['residual'] = [df_final['phasor_diff1'][i]- df_final['phasor_diff1_pred'][i] for i in range(len(df_final['phasor_diff1']))]
df_final['Sum_residual_squared'] = df_final['residual']**2

#df_final
#df_final = df_final.reset_index()
df_final

sum(df_final['Sum_residual_squared'])

std_res = sqrt(sum(df_final['Sum_residual_squared'])/(50-2))
std_res



df_final['averaged_error'] = df_final['error']/50
df_final

std_dev_n = sqrt((((sum(df_final['phasor_diff1_pred']**2)*50)) - (sum(df_final['phasor_diff1_pred'])**2))/ (50*(50-1)))
std_dev_n
#std_dev_n = sqrt(((sum(df_final['phasor_diff1_pred']**2)*4186)-(sum(df_final['phasor_diff1_pred'])**2))/(4186))

#std_dev_k = sqrt((((sum(df_final['phasor_diff1_pred']**2)*32)) - (sum(df_final['phasor_diff1_pred'])**2))/ (32*(32-1)))
#std_dev_k

standard_dev = df_final['phasor_diff1_pred'].std()
print('standard dev. for each step n ahead: %f' % standard_dev)

df_final['std_dev_n'] = df_final['phasor_diff1_pred'].rolling(window=2).std()
df_final

df_final['e_n'] = df_final['error']/df_final['std_dev_n']
df_final

df_final['a_k'] = df_final['averaged_error']/standard_dev
df_final

df_final2 = df_final.reset_index()

rcParams['figure.figsize'] = 10, 5

df_final2[['e_n','a_k']].plot()

plt.ticklabel_format(style = 'plain')

plt.xlabel('steps', family='Arial', fontsize=13)
#plt.ylabel('Phasor Difference', family='Arial', fontsize=10)
#plt.xticks(rotation=45, fontsize=8)
plt.show()

df_final3 = df_final.reset_index()
steps = df_final3.head(50)
steps

#steps= steps.drop(['index'], axis=1)
#steps

#steps = steps.reset_index()
steps[['e_n','a_k']].plot()

plt.xlabel('steps', family='Arial', fontsize=10)
#plt.ylabel('Phasor Difference', family='Arial', fontsize=10)
#plt.xticks(rotation=45, fontsize=8)
plt.show()

steps['error'].plot()

plt.xlabel('steps', family='Arial', fontsize=10)
plt.ylabel('error', family='Arial', fontsize=10)
#plt.ylabel('Phasor Difference', family='Arial', fontsize=10)
#plt.xticks(rotation=45, fontsize=8)
plt.show()

steps.head(10)

# Set plot size 
#from pylab import rcParams
rcParams['figure.figsize'] = 13, 5

# Plot parameters
#START_DATE_FOR_PLOTTING = '2020-09-30 00:00:00'
df_final6 = df_final.copy()
steps5 = df_final6.head(20)

final_df1 = final_df.copy()
#other_df_copy = other_df.copy()
final_df1 = final_df1.reset_index()
time_steps = (final_df1['time'] >= ('2020-09-29 08:00:00')) & (final_df1['time'] <= ('2020-09-30 11:00:00'))
steps6 = final_df1.loc[time_steps]
steps6 = steps6.set_index('time')


plt.plot(steps6['phasor_diff1'], color='b', label='actual values', linewidth=1.5)
#plt.plot(df_0['phasor_diff1_train'], color='orange', label='Train data', linewidth=1)
#plt.plot(test['phasor_diff1'], label='Test data', linewidth=0.7)
#plt.plot(steps5['phasor_diff1'], color='b', label='test data',linewidth=1.5, linestyle='--')
plt.plot(steps5['phasor_diff1_pred'], color='red', label='forecasted values',linewidth=1.5)

ci = 1.960 * np.std(steps5['phasor_diff1_pred']) / np.mean(steps5['phasor_diff1_pred'])
ci2 = 1.282 * np.std(steps5['phasor_diff1_pred']) / np.mean(steps5['phasor_diff1_pred'])

#plt.plot(steps5['phasor_diff1_pred'].index, y)
plt.fill_between(steps5['phasor_diff1_pred'].index, (steps5['phasor_diff1_pred']-ci), (steps5['phasor_diff1_pred']+ci), color='orange', alpha=0.1)

plt.fill_between(steps5['phasor_diff1_pred'].index, (steps5['phasor_diff1_pred']-ci2), (steps5['phasor_diff1_pred']+ci2), color='brown', alpha=0.1)


plt.axvline(x = max(steps6.index), color='grey', linewidth=2, linestyle='--')

plt.grid(which='major', color='#cccccc', alpha=0.5)

plt.legend(shadow=True)
#plt.title('Predcitions and Acutal values', family='Arial', fontsize=12)
plt.xlabel('time', family='Arial', fontsize=13)
plt.ylabel('Phasor Difference', family='Arial', fontsize=13)
plt.xticks(rotation=45, fontsize=8)
plt.show()